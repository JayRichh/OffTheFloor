{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bd3428-99f6-487d-877c-8f91adea51ae",
   "metadata": {},
   "source": [
    "# Export Weights\n",
    "\n",
    "If you haven't created a model checkpoint (e.g. model-checkpoint.h5) first go to the Train_Model.ipynb notebook, train a model, and then come back here.\n",
    "\n",
    "This notebook will export a trained Tensorflow model to JSON weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709045aa-0e87-499b-9e63-c263a5621526",
   "metadata": {},
   "source": [
    "### Tensorflow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72922059-0f22-467c-abe3-9bc23139adc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-10T02:09:49.430060Z",
     "iopub.status.busy": "2023-09-10T02:09:49.429813Z",
     "iopub.status.idle": "2023-09-10T02:09:49.436398Z",
     "shell.execute_reply": "2023-09-10T02:09:49.434670Z",
     "shell.execute_reply.started": "2023-09-10T02:09:49.430033Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169885d7-bfa5-4297-a8c3-e9f559d73b14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-10T02:09:53.285979Z",
     "iopub.status.busy": "2023-09-10T02:09:53.285461Z",
     "iopub.status.idle": "2023-09-10T02:09:53.549422Z",
     "shell.execute_reply": "2023-09-10T02:09:53.547912Z",
     "shell.execute_reply.started": "2023-09-10T02:09:53.285939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.2\n",
      "Detected GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Detected GPUs:\", len(gpus))\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a5351-7e86-4674-8044-c43019e842c9",
   "metadata": {},
   "source": [
    "### Redefine the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37a2821-ab98-4797-a37b-93b4e7df80ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-10T02:09:56.458035Z",
     "iopub.status.busy": "2023-09-10T02:09:56.457541Z",
     "iopub.status.idle": "2023-09-10T02:09:56.478298Z",
     "shell.execute_reply": "2023-09-10T02:09:56.476967Z",
     "shell.execute_reply.started": "2023-09-10T02:09:56.457999Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import RandomNormal\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "#Modified depth_to_space shuffle order for easier shader generation\n",
    "class DepthToSpace2(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_depth, **kwargs):\n",
    "        super(DepthToSpace2, self).__init__(**kwargs)\n",
    "        self.input_depth = input_depth\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(DepthToSpace2, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        x = tf.split(x, (self.input_depth // 4), axis=-1)\n",
    "        return tf.concat([tf.nn.depth_to_space(xx, 2) for xx in x], axis=-1)\n",
    "\n",
    "\n",
    "#SR model that doubles image size\n",
    "def SR2Model(input_texture=\"MAIN\", input_depth=3, highway_depth=4, block_depth=4, init='he_normal', init_last = RandomNormal(mean=0.0, stddev=0.001)):\n",
    "\n",
    "    input_shape = [None, None, input_depth]\n",
    "    #Add \".MAIN\" in layer name as flag for shader generation, this makes the input act as the MAIN texture\n",
    "    input_lr = tf.keras.layers.Input(shape=input_shape, name=\"input.\" + input_texture)\n",
    "    input_lr2 = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(input_lr)\n",
    "    \n",
    "\n",
    "    x = input_lr\n",
    "    for i in range(block_depth):\n",
    "        x = tf.keras.layers.Conv2D(highway_depth, (3, 3), padding='same', kernel_initializer=init)(x)\n",
    "        x = tf.nn.crelu(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(highway_depth, (3, 3), padding='same', name=\"conv2d_last\",  kernel_initializer=init)(x)\n",
    "    \n",
    "    \n",
    "    #Add \"lastresid\" in layer name as flag for shader generation, this allows the shader to combine the convolution with the residual add as one layer for faster performance\n",
    "    #Add \".MAIN\" in layer name to make the layer save to the MAIN texture\n",
    "    x = DepthToSpace2(4, name=\"depth_to_space2_lastresid.\" + input_texture)(x)\n",
    "\n",
    "    \n",
    "    #Add \".ignore\" in layer name as flag for shader generation, this will ignore the layer, as the residual will be added by the previous \"lastresid\" layer\n",
    "    x = tf.keras.layers.Add(name=\"add.ignore.\" + input_texture)([x, input_lr2])\n",
    "\n",
    "    model = tf.keras.models.Model(input_lr, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b7d177e-7e9e-461b-83d4-60146f323250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-10T02:10:06.723110Z",
     "iopub.status.busy": "2023-09-10T02:10:06.722628Z",
     "iopub.status.idle": "2023-09-10T02:10:08.006891Z",
     "shell.execute_reply": "2023-09-10T02:10:08.005274Z",
     "shell.execute_reply.started": "2023-09-10T02:10:06.723073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                    Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      " input.MAIN (InputLayer)                         [(None, None, None, 3)]          0                 []                                                \n",
      "                                                                                                                                                      \n",
      " conv2d (Conv2D)                                 (None, None, None, 4)            112               ['input.MAIN[0][0]']                              \n",
      "                                                                                                                                                      \n",
      " tf.compat.v1.nn.crelu (TFOpLambda)              (None, None, None, 8)            0                 ['conv2d[0][0]']                                  \n",
      "                                                                                                                                                      \n",
      " conv2d_1 (Conv2D)                               (None, None, None, 4)            292               ['tf.compat.v1.nn.crelu[0][0]']                   \n",
      "                                                                                                                                                      \n",
      " tf.compat.v1.nn.crelu_1 (TFOpLambda)            (None, None, None, 8)            0                 ['conv2d_1[0][0]']                                \n",
      "                                                                                                                                                      \n",
      " conv2d_2 (Conv2D)                               (None, None, None, 4)            292               ['tf.compat.v1.nn.crelu_1[0][0]']                 \n",
      "                                                                                                                                                      \n",
      " tf.compat.v1.nn.crelu_2 (TFOpLambda)            (None, None, None, 8)            0                 ['conv2d_2[0][0]']                                \n",
      "                                                                                                                                                      \n",
      " conv2d_last (Conv2D)                            (None, None, None, 4)            292               ['tf.compat.v1.nn.crelu_2[0][0]']                 \n",
      "                                                                                                                                                      \n",
      " depth_to_space2_lastresid.MAIN (DepthToSpace2)  (None, None, None, 1)            0                 ['conv2d_last[0][0]']                             \n",
      "                                                                                                                                                      \n",
      " up_sampling2d (UpSampling2D)                    (None, None, None, 3)            0                 ['input.MAIN[0][0]']                              \n",
      "                                                                                                                                                      \n",
      " add.ignore.MAIN (Add)                           (None, None, None, 3)            0                 ['depth_to_space2_lastresid.MAIN[0][0]',          \n",
      "                                                                                                     'up_sampling2d[0][0]']                           \n",
      "                                                                                                                                                      \n",
      "======================================================================================================================================================\n",
      "Total params: 988\n",
      "Trainable params: 988\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.reset_uids()\n",
    "model = SR2Model(input_texture=\"MAIN\", input_depth=3, highway_depth=4, block_depth=3)\n",
    "model.summary(line_length=150)\n",
    "model.load_weights(\"model-checkpoint.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66efcfbf-6dab-4bf7-a0d0-10202c401032",
   "metadata": {},
   "source": [
    "### Generate GLSL files\n",
    "\n",
    "This code comes directly from the Anime4K repository. We first write weights to `.glsl`files before compiling a `.json` weights file. This is roundabout, but I wrote the parsing script originally to parse the weights from the `.glsl` files, and also Anime4K doesn't have Tensorflow model weights for it's networks, only the weights from the `.glsl` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d1a6fa-eb73-4dfb-b50a-ee71e1e6481f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-10T02:10:21.222843Z",
     "iopub.status.busy": "2023-09-10T02:10:21.222080Z",
     "iopub.status.idle": "2023-09-10T02:10:21.247263Z",
     "shell.execute_reply": "2023-09-10T02:10:21.246036Z",
     "shell.execute_reply.started": "2023-09-10T02:10:21.222812Z"
    }
   },
   "outputs": [],
   "source": [
    "from shaderutils import gen_shader\n",
    "gen_shader(model, hook=\"MAIN\", file=\"cnn-2x-custom.glsl\", desc=\"Upscale\", when=\"OUTPUT.w MAIN.w / 1.200 > OUTPUT.h MAIN.h / 1.200 > *\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12d02d-c896-405c-8a14-20adf3cfc080",
   "metadata": {},
   "source": [
    "### Convert GLSL to JSON\n",
    "This script convers the GLSL file to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4820457b-a012-49d1-8c85-3b339c23b9ca",
   "metadata": {},
   "source": [
    "First, we have a layer class as a utility file which does most of the parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d039a-6e00-4c4a-8265-ae5a57c756b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    def __init__(self, raw_text):\n",
    "        [descriptor, code] = raw_text.split('//!WHEN OUTPUT.w MAIN.w / 1.200 > OUTPUT.h MAIN.h / 1.200 > *\\n')\n",
    "\n",
    "        self.parse_fields(descriptor)\n",
    "\n",
    "        if(self.type == \"conv\"):\n",
    "            self.parse_code(code)\n",
    "\n",
    "\n",
    "\n",
    "    def parse_code(self, code):\n",
    "        print(\"Name: {}, Input: {}, Outputs: {}\".format(self.name, self.inputs, self.output))\n",
    "\n",
    "        main_fn = code.split('vec4 hook() {\\n')[1].split('\\n    return result;')[0]\n",
    "\n",
    "        lines = main_fn.split('\\n')\n",
    "\n",
    "        convolutions = lines[:-1]\n",
    "        bias = lines[-1]\n",
    "        \n",
    "        print(len(convolutions))\n",
    "        assert (len(convolutions)%9 == 0)\n",
    "        assert (int(len(convolutions)/9) == len(self.inputs) or int(len(convolutions)/9) == len(self.inputs)*2)\n",
    "        self.double_input = int(len(convolutions)/9) == len(self.inputs)*2\n",
    "\n",
    "        self.weights = []\n",
    "\n",
    "        for i, line in enumerate(convolutions):\n",
    "\n",
    "            weights = line.split('mat4(')[1].split(')')[0].split(',')\n",
    "            assert (len(weights) == 16)\n",
    "\n",
    "            for w in weights:\n",
    "                self.weights.append(float(w))\n",
    "\n",
    "\n",
    "        self.bias = [float(b) for b in bias.split('vec4(')[1].split(')')[0].split(',')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def parse_outputs(self, fields):\n",
    "\n",
    "        for field in fields:\n",
    "            parts = field.split(' ')\n",
    "            field_name = parts[0][3:]\n",
    "            field_value = parts[1]\n",
    "\n",
    "\n",
    "\n",
    "            if(field_name == \"SAVE\"):\n",
    "                if(field_value== \"MAIN\"):\n",
    "                    self.name = \"pixel_shuffle\"\n",
    "                    self.type = \"pixel_shuffle\"\n",
    "                    self.output = \"canvas\"\n",
    "                else:\n",
    "                    self.name = field_value\n",
    "                    self.type = \"conv\"\n",
    "                    self.output = field_value\n",
    "\n",
    "\n",
    "    def parse_inputs(self, fields):\n",
    "\n",
    "\n",
    "        for field in fields:\n",
    "            parts = field.split(' ')\n",
    "            field_name = parts[0][3:]\n",
    "            field_value = parts[1]\n",
    "\n",
    "            if(field_name == \"BIND\"):\n",
    "                if(field_value == \"MAIN\"):\n",
    "                    if(self.output != \"canvas\"):\n",
    "                        self.inputs.append(\"input_image\")\n",
    "\n",
    "                else:\n",
    "                    self.inputs.append(field_value)\n",
    "\n",
    "\n",
    "    def parse_fields(self, descriptor):\n",
    "\n",
    "        fields = descriptor.split(\"\\n\")[1:-1]\n",
    "\n",
    "\n",
    "        self.inputs = []\n",
    "        self.parse_outputs(fields)\n",
    "        self.parse_inputs(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888af048-50dd-4083-b77b-e376b159e265",
   "metadata": {},
   "source": [
    "Next we define the process file. Adjust the output filename as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cef824-e5ae-47a8-b83f-cae65582940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def process_file(fname):\n",
    "\n",
    "    f = open(fname)\n",
    "    text = f.read()\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    raw_layers = text.split('!DESC')[1:]\n",
    "\n",
    "    layers = [Layer(raw_layer) for raw_layer in raw_layers]\n",
    "\n",
    "    network_dict = {\n",
    "        'name': 'anime4k/cnn-2x-s',\n",
    "        'layers': {}\n",
    "    }\n",
    "\n",
    "    for layer in layers:\n",
    "        layer_dict = {\n",
    "            'name': layer.name,\n",
    "            'type': layer.type,\n",
    "            'inputs': layer.inputs,\n",
    "            'output': layer.output\n",
    "        }\n",
    "\n",
    "        if(layer.type == 'conv'):\n",
    "\n",
    "            layer_dict['weights'] = layer.weights\n",
    "\n",
    "            layer_dict['bias'] = layer.bias\n",
    "\n",
    "        network_dict['layers'][layer.name] = layer_dict\n",
    "\n",
    "    f = open('{}-custom.json'.format(network_dict['name'].replace('/', '-')), 'w')\n",
    "    json.dump(network_dict, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2343aa-9c58-484b-b6a2-59bf0ebfd203",
   "metadata": {},
   "source": [
    "Run the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f97323-9e0a-4463-8ac7-57f13bd910b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file('cnn-2x-custom.glsl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
